(this["webpackJsonpsabri-site"]=this["webpackJsonpsabri-site"]||[]).push([[0],[,,,,,,,,,,,,,,function(e,t,a){"use strict";a.r(t),a.d(t,"DATA",(function(){return r}));var r={research:[{id:"cartridges",title:"Cartridges: Lightweight and general-purpose languge model memory via self-study",authors:["Sabri Eyuboglu*","Ryan Ehrlich*","Simran Arora*","Neel Guha","Dylan Zinsley","Emily Liu","Will Tennien","Atri Rudra","James Zou","Azalia Mirhoseini","Christopher R\xe9"],venues:[{name:"Preprint",year:"2025",notes:[""]}],image:"res/domino_preview.png",github:"https://github.com/HazyResearch/cartridges",manuscript:"https://arxiv.org/abs/2506.06266",description:"When we put lots of text (e.g. a whole code repo) into a language model\u2019s context, generation cost soars because of the KV cache\u2019s size. What if we trained a smaller KV cache for our documents offline? Using a test-time training recipe called self-study, we show that this simple idea can improve throughput by 26x while maintaining quality.",links:{"\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2025-06-08-cartridges"},pinned:!0},{id:"minions",title:"Minions: Cost-efficient collaboration between on-device and cloud language models",authors:["Avanika Narayan*","Dan Biderman*","Sabri Eyuboglu*","Avner May","Scott Linderman","James Zou","Christopher R\xe9"],venues:[{name:"ICML",year:"2025",notes:[""]}],image:"res/domino_preview.png",github:"https://github.com/HazyResearch/minions",manuscript:"https://arxiv.org/abs/2502.15964",description:"We shift a substantial portion of LLM workloads to consumer devices by having small on-device models collaborate with frontier models in the cloud. By only reading long contexts locally, we reduce cloud costs with minimal or no quality degradation.",links:{"\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2025-02-24-minions"},pinned:!0},{id:"rana",title:"Adaptive Rank Allocation: Speeding up modern transformers with RaNA adapters",authors:["Roberto Garcia","Jerry Liu","Daniel Sorvisto","Sabri Eyuboglu"],venues:[{name:"ICLR",year:"2025",notes:[""]}],image:"res/domino_preview.png",github:"https://github.com/HazyResearch",manuscript:"https://openreview.net/forum?id=uAtDga3q0r",description:"One way to speedup LLMs is by dynamically dropping neurons from MLPs at test time. However, due to superposition, sparsity in neurons may be hard to find. Instead, we learn to drop ranks from the SVD of any linear projetion, which provides larger speedups at the same accuracy.",links:{},pinned:!1},{id:"layer-looping",title:"Towards smaller language models via layer looping",authors:["Sabri Eyuboglu","Dylan Zinsley","Jon Saad-Falcon","Simran Arora","Atri Rudra","James Zou","Christopher R\xe9"],venues:[{name:"ICML (Efficient Systems for Foundation Models Workshop)",year:"2024",notes:[]}],image:"res/domino_preview.png",github:"https://github.com/HazyResearch/zoology",manuscript:"https://openreview.net/pdf?id=2N3CtUdoB0",description:"Can a Transformer act as an efficient data structure? We show that Transformers cannot efficiently answer complex queries over the factual knowledge in their parameters. However, two simple modifications, looped + conditional computation, improve space + time complexity!",links:{},pinned:!1},{id:"jrt",title:"Just read twice: closing the recall gap for recurrent language models",authors:["Simran Arora","Aman Timalsina","Aaryan Singhal","Benjamin Spector","Sabri Eyuboglu","Xinyi Zhao","Ashish Rao","Atri Rudra","Christopher R\xe9"],manuscript:"https://arxiv.org/abs/2407.05483",github:"https://github.com/HazyResearch/prefix-linear-attention",description:"We show that using a bidirectional encoder and a recurrent decoder (e.g. linear attention) can close some of the recall gap we identified in prior work (Zoology and Based). ",venues:[{name:"ICML (Efficient Systems for Foundation Models Workshop)",year:"2024",notes:[]}],links:{"\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2024-07-01-jrt"}},{id:"based",title:"Simple linear attention models balance the recall-throughput tradeoff",authors:["Sabri Eyuboglu*","Simran Arora*","Michael Zhang*","Aman Timalsina","Silas Alberti","Dylan Zinsley","James Zou","Atri Rudra","Christopher R\xe9"],venues:[{name:"ICML",year:"2024",notes:["Spotlight Presentation"]},{name:"ICML (Efficient Systems for Foundation Models Workshop)",year:"2024",notes:["Best Paper Award"]}],image:"res/domino_preview.png",github:"https://github.com/HazyResearch/based",manuscript:"https://arxiv.org/abs/2402.18668",description:"We highlight a fundamental tradeoff between a language model's memory consumption during generation and it's capacity to perfrom recall (e.g. copying). We show that simple linear attention models sit at the pareto frontier of this tradeoff.",links:{"\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2024-03-03-based","\ud83c\udfa4 ICML Talk":"https://www.youtube.com/watch?v=KCIcBnR-67s"},pinned:!0},{id:"zoology",title:"Zoology: Measuring and improving recall in efficient language models",authors:["Simran Arora*","Sabri Eyuboglu*","Aman Timalsina","Isys Johnson","Michael Poli","James Zou","Atri Rudra","Christopher R\xe9"],venues:[{name:"ICLR",year:"2024",notes:[]}],image:"res/domino_preview.png",github:"https://github.com/HazyResearch/zoology",manuscript:"https://arxiv.org/abs/2312.04927",description:"We explain why a broad class of efficient language model architectures struggle to recall information seen in-context (e.g. copy information from the prompt).",links:{"\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2023-12-11-zoology1-analysis","\ud83c\udfa4 ICLR Talk":"https://iclr.cc/virtual/2024/poster/18860"},pinned:!0},{id:"monarch-mixer",title:"Monarch Mixer: A simple sub-quadratic GEMM-based architecture",authors:["Daniel Y. Fu","Simran Arora*","Jessica Grogan*","Isys Johnson*","Sabri Eyuboglu*","Armin W. Thomas*","Benjamin Spector","Michael Poli","Atri Rudra","Christopher R\xe9"],venues:[{name:"NeurIPS",year:"2023",notes:["Oral Presentation"]}],image:"res/domino_preview.png",github:"https://github.com/HazyResearch/evaporate",manuscript:"https://arxiv.org/abs/2304.09433",description:"We swap out the attention and MLPs in a Transformer with fast, structured matrices that can be computed in sub-quadratic time.",links:{"\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2023-04-12-batch"},pinned:!1},{id:"evaporate",title:"Language models enable simple systems for generating structured views of heterogeneous data lakes",authors:["Simran Arora","Brandon Yang*","Sabri Eyuboglu*","Avanika Narayan","Andrew Hojel","Immanuel Trummer","Christopher R\xe9"],venues:[{name:"VLDB",year:"2024",notes:[]}],image:"res/domino_preview.png",github:"https://github.com/HazyResearch/evaporate",manuscript:"https://arxiv.org/abs/2304.09433",description:"Using LLMs to process unstructured data is expensive. We show how they can be used to generate and evalute code snippets that do the processing at a fraction of the cost.",links:{"\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2023-04-12-batch"},pinned:!1},{id:"model-changelists",title:"Model ChangeLists: Characterizing changes to machine learning APIs",authors:["Sabri Eyuboglu","Karan Goel","Arjun Desai","Lingjiao Chen","Mathew Monfort","Christopher R\xe9","James Zou"],venues:[{name:"FAccT",year:"2024",notes:["Oral Presentation"]}],image:"res/domino_preview.png",github:"https://github.com/HazyResearch/meerkat",manuscript:"",description:'We explore how slice discovery techniques like Domino can be used to create a "ChangeList" comparing two machine learning models (e.g. before and after an update).',links:{},pinned:!1},{id:"hapi",title:"Hapi: A large-scale longitudinal dataset of commercial ml api predictions",authors:["Lingjiao Chen","Zhihua Jin","Sabri Eyuboglu","Christopher R\xe9","Matei Zaharia","James Y. Zou"],venues:[{name:"NeurIPS",year:"2022",notes:["Datasets and Benchmarks"]}],image:"res/domino_preview.png",github:"https://github.com/lchen001/HAPI",manuscript:"https://arxiv.org/abs/2209.08443",description:"We collect predictions from ML-as-a-Service APIs over time and explore how they change.",links:{},pinned:!1},{id:"domino",title:"Domino: Discovering systematic errors with cross-modal embeddings ",authors:["Sabri Eyuboglu*","Maya Varma*","Khaled Saab*","Jean-Benoit Delbrouck","Christopher Lee-Messer","Jared Dunnmon","James Zou","Christopher R\xe9"],venues:[{name:"ICLR",year:"2022",notes:["Oral Presentation"]}],image:"res/domino_preview.png",github:"https://github.com/HazyResearch/domino/tree/main/domino",manuscript:"https://arxiv.org/abs/2203.14960",description:"We show how you can use multi-modal foundation models to discover the systematic errors made by machine learning models.",links:{"\ud83c\udf0d Blog post":"https://ai.stanford.edu/blog/domino/","\ud83c\udfa4 ICLR talk":"https://iclr.cc/virtual/2022/oral/6149"},pinned:!0},{id:"dcbench",title:"DCBench: A benchmark for data-centric AI systems",authors:["Sabri Eyuboglu*","Bojan Karla\u0161*","Christopher R\xe9","Ce Zhang","James Zou"],venues:[{name:"DEEM",year:"2022",notes:["Best Presentation Award"]}],image:"res/hapi-preview.png",description:"We create a benchmark for the parts of the machine-learning lifecycle beyond model training (e.g. data selection, subgroup analysis, data cleaning).",github:"https://github.com/data-centric-ai/dcbench",manuscript:"https://dl.acm.org/doi/abs/10.1145/3533028.3533310",links:{"\ud83c\udf0d Website":"https://www.datacentricai.cc/benchmark/","\ud83c\udfa5 Demo":"https://drive.google.com/file/d/1BVLfPuXfqldrdJd1WI1SRBlcklcOyNC5/view"}},{id:"mutual-interactors",title:"Mutual interactors as a principle for the discovery of phenotypes in molecular networks",authors:["Sabri Eyuboglu*","Marinka Zitnik*","Jure Leskovec"],venues:[{name:"PSB",year:"2023",notes:["Oral Presentation"]}],image:"res/mi_preview.png",description:"We show that a super simple network principle can be used to identify disease-related genes.",manuscript:"https://cs.stanford.edu/people/sabrieyuboglu/psb-mi.pdf",github:"https://github.com/seyuboglu/milieu",links:{"\ud83c\udfa4 PSB talk":"https://youtu.be/WAE3spTP9PI","\ud83d\udedd Slides":"https://drive.google.com/file/d/1268p4qqwSP48MlQGtemnsenkz4iRYz18/view?usp=sharing"},pinned:!1},{id:"pet-ct",title:"Multi-task weak supervision enables anatomically-resolved abnormality detection in whole-body FDG-PET/CT",authors:["Sabri Eyuboglu*","Geoffrey Angus*","Bhavik Patel","Anuj Pareek","Guido Davidzon","Jin Long","Jared Dunnmon**","Matthew Lungren**"],venues:[{name:"Nature Communications",year:"2021",notes:[]}],image:"res/pet_ct_preview.png",github:"https://github.com/seyuboglu/weakly-supervised-petct",manuscript:"https://www.nature.com/articles/s41467-021-22018-1",description:"We train language models to read complicated radiology reports and use them to train multi-task models that can detect fine-grained abnormalities in large scans.",links:{},pinned:!1}],teaching:[{title:"Computa\xe7\xe3o no Ensino Medio",organization:"Sabri Eyuboglu and Geoffrey Angus",year:"2018",school:"Col\xe9gio SESC S\xe3o Jose \u2013 Curitiba, Brasil",image:"res/cem_preview.png",description:" I spent the summer of 2018 in Curitiba, Brazil teaching an introductory computer science course to over 300 awesome high schoolers from all over the city. Every week Geoff Angus (another master's student at Stanford) and I co-taught eleven different classes at three different high schools in the city. We designed a full curriculum from scratch that uses the methods of CS106A, but is tailored for high-school students that speak English as a second language. We wrote all of the assignments, course notes and slides from scratch. You can find all these materials on our website. We worked with school administrators and math teachers at the high schools to ensure the continuation of CS curriculum at the high school after we left. Also, because many students spoke little english, we lectured primarily in Portuguese (I had spent the school year before that summer studying Portuguese in preparation",github:"https://github.com/geoffreyangus/cs106r",website:"http://cs106r.com/",links:{"\ud83d\udcbb GitHub":"https://github.com/geoffreyangus/cs106r"}},{title:"CS 198 Section Leader",organization:"Computer Science Department",year:"2015-2018",school:"Stanford University",image:"res/cem_preview.png",description:"From sophomore to senior year of undergrad, I was a CS 106A/B section leader at Stanford. I taught a weekly class of twelve students, graded assignments and held office hours.",github:"https://github.com/geoffreyangus/cs106r",website:"http://web.stanford.edu/class/cs106b/",links:{"\ud83c\udf0d Website":"http://web.stanford.edu/class/cs106b/"}},{title:"CS Bridge Section Leader",organization:"Computer Science Department",year:"2019",school:"Ko\xe7 University \u2013 Istanbul, Turkey",image:"res/cem_preview.png",description:"I spent two weeks this past summer in Istanbul teaching computer science at Ko\xe7 University. I helped develop some of the curriculum and materials for the course.",github:"https://github.com/geoffreyangus/cs106r",website:"https://koc.csbridge.org/en/index.html",links:{"\ud83c\udf0d Website":"https://koc.csbridge.org/en/index.html"}}],software:[{id:"meerkat",title:"meerkat",banner:"software/meerkat/meerkat_banner_small.png",description:"Meerkat is an open-source Python library that helps users visualize, explore, and annotate any dataset.",github:"https://github.com/HazyResearch/meerkat",docs:"http://cs106r.com/",pypi:"meerkat-ml",install:"http://meerkat.wiki/docs/start/install.html",links:{"\ud83d\udcbb GitHub":"https://github.com/HazyResearch/meerkat","\ud83d\udcd8 Docs":"http://meerkat.wiki/docs/index.html","\ud83c\udf0d Blog post":"http://meerkat.wiki/blog"}},{id:"zoology-software",title:"zoology",banner:"software/zoology/zoology_banner_small.png",description:"Zoology provides a simple playground for understanding and testing language models on synthetic tasks.",github:"https://github.com/HazyResearch/zoology",docs:"http://cs106r.com/",pypi:"meerkat-ml",install:"http://meerkat.wiki/docs/start/install.html",links:{"\ud83d\udcbb GitHub":"https://github.com/HazyResearch/zoology","\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2023-12-11-zoology1-analysis"}},{id:"minions-software",title:"minions",banner:"software/minions/minions_banner_small.png",description:"Minions provides communication protocols for on-device and cloud language models to collaborate.",github:"https://github.com/HazyResearch/minions",docs:"http://cs106r.com/",pypi:"minions",install:"http://meerkat.wiki/docs/start/install.html",links:{"\ud83d\udcbb GitHub":"https://github.com/HazyResearch/minions","\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2025-02-24-minions"}},{id:"based-software",title:"based",banner:"software/based/based_banner.png",description:"Training and evaluation for training simple, linear attention variants.",github:"https://github.com/HazyResearch/based",docs:"http://cs106r.com/",pypi:"minions",install:"http://meerkat.wiki/docs/start/install.html",links:{"\ud83d\udcbb GitHub":"https://github.com/HazyResearch/based","\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2024-03-03-based"}},{id:"cartridges-software",title:"cartridges",banner:"software/cartridges/cartridges_banner.png",description:"Store huge contexts in tiny KV caches with a synthetic data recipe called self-study.",github:"https://github.com/HazyResearch/cartridges",docs:"http://cs106r.com/",pypi:"minions",install:"http://meerkat.wiki/docs/start/install.html",links:{"\ud83d\udcbb GitHub":"https://github.com/HazyResearch/cartridges","\ud83c\udf0d Blog post":"https://hazyresearch.stanford.edu/blog/2025-06-08-cartridges"}},{id:"tokasaurus",title:"tokasaurus",banner:"software/tokasaurus/toka-banner.png",description:"An LLM inference engine optimized for throughput-intensive workloads.",github:"https://github.com/ScalingIntelligence/tokasaurus",docs:"http://cs106r.com/",pypi:"minions",install:"http://meerkat.wiki/docs/start/install.html",links:{"\ud83d\udcbb GitHub":"https://github.com/ScalingIntelligence/tokasaurus","\ud83c\udf0d Blog post":"https://scalingintelligence.stanford.edu/blogs/tokasaurus/"}}]}},,,,,,,,,function(e,t,a){e.exports=a(43)},,,,,function(e,t,a){},function(e,t,a){},function(e,t,a){var r={"./home":14,"./home.js":14,"./software/based/based_banner.png":31,"./software/cartridges/cartridges_banner.png":32,"./software/meerkat/meerkat_banner_small.png":33,"./software/minions/minions_banner_small.png":34,"./software/tokasaurus/toka-banner.png":35,"./software/zoology/zoology_banner.png":36,"./software/zoology/zoology_banner_small.png":37};function s(e){var t=i(e);return a(t)}function i(e){if(!a.o(r,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return r[e]}s.keys=function(){return Object.keys(r)},s.resolve=i,e.exports=s,s.id=30},function(e,t,a){e.exports=a.p+"static/media/based_banner.8cdf3638.png"},function(e,t,a){e.exports=a.p+"static/media/cartridges_banner.52799963.png"},function(e,t,a){e.exports=a.p+"static/media/meerkat_banner_small.45d40774.png"},function(e,t,a){e.exports=a.p+"static/media/minions_banner_small.52a63c9e.png"},function(e,t,a){e.exports=a.p+"static/media/toka-banner.8c5398c1.png"},function(e,t,a){e.exports=a.p+"static/media/zoology_banner.3210a781.png"},function(e,t,a){e.exports=a.p+"static/media/zoology_banner_small.10588f65.png"},,,,,,function(e,t,a){"use strict";a.r(t);var r=a(0),s=a.n(r),i=a(20),n=a.n(i),o=a(10),l=a(9);Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));a(28);var c=a(1),h=a(2),d=a(4),p=a(3),m=(a(29),a(11)),u=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(e){var r;return Object(c.a)(this,a),(r=t.call(this,e)).state={charLimit:e.charLimit},r.initialState=r.state,r}return Object(h.a)(a,[{key:"getReadMoreContent",value:function(){var e=this.state.charLimit,t=this.props,a=t.children,r=t.readMoreText,i=t.readLessText;return a.length>e?s.a.createElement("span",{className:"short-text"},a.substr(0,e),"...",s.a.createElement("span",{className:"readMoreText",style:{color:"#007bff",cursor:"pointer"},role:"presentation",onClick:this.showLongText.bind(this)},r)):a.length<e?s.a.createElement("span",{className:"short-text"},a):s.a.createElement("span",{className:"short-text"},a,s.a.createElement("span",{className:"readMoreText",style:{color:"#007bff",cursor:"pointer"},role:"presentation",onClick:this.showShortText.bind(this)},i))}},{key:"showLongText",value:function(){var e=this.props.children;this.setState({charLimit:e.length}),this.getReadMoreContent()}},{key:"showShortText",value:function(){this.setState(this.initialState),this.getReadMoreContent()}},{key:"render",value:function(){return s.a.createElement("div",null,this.getReadMoreContent())}}]),a}(s.a.Component);u.defaultProps={charLimit:100,readMoreText:" Read More",readLessText:" Read Less"};var g=u,b=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(h.a)(a,[{key:"render",value:function(){var e=this.props,t=e.id,a=e.title,r=e.authors,i=e.venues,n=(e.image,e.description),o=e.github,l=e.manuscript,c=e.links,h=e.highlighted;o||(o="https://github.com/seyuboglu");for(var d=[],p=0,u=Object.entries(c);p<u.length;p++){var g=Object(m.a)(u[p],2),b=g[0],f=g[1];d.push(s.a.createElement("a",{href:f},s.a.createElement("div",{class:"text-button"},b)))}for(var y=[],w=0;w<i.length;w++){for(var v=i[w],E=[],k=0;k<v.notes.length;k++)E.push(s.a.createElement("span",{className:"note-tag"},v.notes[k]));y.push(s.a.createElement("div",{className:"card-body-venue"},s.a.createElement("i",null,v.name),""!=v.year?", "+v.year:"","  ",E," ",s.a.createElement("br",null)))}var C=r.findIndex((function(e){return e.includes("Sabri Eyuboglu")}));return s.a.createElement("div",{className:"concept-card ".concat(h?"highlighted":""),id:"card-".concat(t)},s.a.createElement("div",{className:"card-body"},s.a.createElement("a",{href:l},s.a.createElement("div",{className:"card-body-title"},a)),s.a.createElement("div",{className:"card-body-authors"},0!=C?r.slice(0,C).join(", ")+",":""," ",s.a.createElement("b",null,r[C]),C!=r.length-1?",":""," ",r.slice(C+1).join(", ")),y,s.a.createElement("div",{className:"card-body-links"},s.a.createElement("a",{href:l},s.a.createElement("div",{class:"text-button"},"\ud83d\udcc4 Paper ")),s.a.createElement("a",{href:o},s.a.createElement("div",{class:"text-button"},"\ud83d\udcbb GitHub ")),d),s.a.createElement("div",{className:"card-body-abstract"},s.a.createElement("b",null,"tl;dr"),"       ",n)))}}]),a}(s.a.Component),f=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(h.a)(a,[{key:"render",value:function(){var e=this.props,t=e.title,a=e.organization,r=e.school,i=e.year,n=(e.image,e.description),o=e.github,l=e.website,c=e.links;o||(o="https://github.com/seyuboglu");for(var h=[],d=0,p=Object.entries(c);d<p.length;d++){var u=Object(m.a)(p[d],2),b=u[0],f=u[1];h.push(s.a.createElement("a",{href:f},s.a.createElement("div",{class:"text-button"},b)))}return s.a.createElement("div",{className:"concept-card"},s.a.createElement("div",{className:"card-body"},s.a.createElement("a",{href:l},s.a.createElement("div",{className:"card-body-title"},t)),s.a.createElement("div",{className:"card-body-authors"},a),s.a.createElement("div",{className:"card-body-venue"},s.a.createElement("i",null,r)),s.a.createElement("div",{className:"card-body-venue"},i," ",s.a.createElement("br",null)),s.a.createElement("div",{className:"card-body-links"},h),s.a.createElement("div",{className:"card-body-abstract"},s.a.createElement("b",null,"Abstract."),s.a.createElement(g,null,n))))}}]),a}(b),y=function(e){Object(d.a)(r,e);var t=Object(p.a)(r);function r(e){var a;return Object(c.a)(this,r),(a=t.call(this,e)).state={stars:null},a}return Object(h.a)(r,[{key:"componentDidMount",value:function(){var e=this;if(this.props.github){var t=this.props.github.split("github.com/")[1];fetch("https://api.github.com/repos/".concat(t)).then((function(e){return e.json()})).then((function(t){e.setState({stars:t.stargazers_count})})).catch((function(e){return console.error("Error fetching stars:",e)}))}}},{key:"render",value:function(){var e=this.props,t=e.id,r=e.title,i=e.banner,n=e.description,o=e.github,l=(e.docs,e.pypi,e.website),c=e.links,h=e.highlighted;o||(o="https://github.com/seyuboglu");for(var d=[],p=0,u=Object.entries(c);p<u.length;p++){var g=Object(m.a)(u[p],2),b=g[0],f=g[1];d.push(s.a.createElement("a",{href:f},s.a.createElement("div",{className:"text-button"},b)))}return s.a.createElement("div",{className:"concept-card ".concat(h?"highlighted":""),id:"card-".concat(t)},s.a.createElement("div",{className:"card-body"},s.a.createElement("div",{className:"software-card-body-title"},r),s.a.createElement("div",{className:"card-body-links"},d),s.a.createElement("div",{className:"card-body-abstract"},s.a.createElement("b",null,"tl;dr"),"       ",n)),s.a.createElement("a",{href:l,className:"banner-image-container"},s.a.createElement("img",{className:"banner-image",src:a(30)("./"+i)})))}}]),r}(b),w=0,v=new Map,E=function(e){var t=e.cardId,a=e.onHover,r=e.onLeave,i=e.showAllPapers,n=e.togglePapersView,o=e.researchData;v.has(t)||(w++,v.set(t,w));var l=v.get(t),c=null===o||void 0===o?void 0:o.find((function(e){return e.id===t})),h=c&&!c.pinned&&!i;return s.a.createElement("a",{href:"#card-".concat(t),className:"citation-link ".concat(h?"citation-hidden":""),onMouseEnter:function(){return a(t)},onMouseLeave:r,onClick:function(e){h&&(e.preventDefault(),n(),setTimeout((function(){var e=document.getElementById("card-".concat(t));e&&e.scrollIntoView({behavior:"smooth",block:"center",inline:"nearest"})}),200))},title:h?"Click to show all papers":""},l)},k=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){var e;return Object(c.a)(this,a),(e=t.call(this)).listenToScroll=function(){var t=(document.body.scrollTop||document.documentElement.scrollTop)/(document.documentElement.scrollHeight-document.documentElement.clientHeight);e.setState({scrolled:t>0})},e.state={scrolled:!1},e}return Object(h.a)(a,[{key:"componentDidMount",value:function(){w=0,v.clear(),window.addEventListener("scroll",this.listenToScroll)}},{key:"componentWillUnmount",value:function(){window.removeEventListener("scroll",this.listenToScroll)}},{key:"render",value:function(){return s.a.createElement("div",{id:"navbar",className:this.state.scrolled?"navbar scroll":"navbar"},s.a.createElement("img",{className:"navbar-image",src:"/main.jpeg"}),s.a.createElement("div",{className:"navbar-info"},s.a.createElement("div",{className:"navbar-name"}," Sabri Eyuboglu"),s.a.createElement("div",{className:"navbar-email"},"eyuboglu ",s.a.createElement("b",null,s.a.createElement("i",null,"at"))," stanford ",s.a.createElement("b",null,s.a.createElement("i",null,"dot"))," edu"),s.a.createElement("div",{className:"text-section"},s.a.createElement("p",null,s.a.createElement("b",null,"PhD candidate")," Computer Science ",s.a.createElement("br",null),"Stanford University"),s.a.createElement("p",null,s.a.createElement("b",null,"B.S. + M.S.")," Computer Science ",s.a.createElement("br",null),"Stanford University '19")),s.a.createElement("div",{className:"social-links"},s.a.createElement("a",{href:"https://github.com/seyuboglu"},s.a.createElement("div",{className:"external-link github-link"}," ")),s.a.createElement("a",{href:"https://www.linkedin.com/in/evan-sabri-eyuboglu-21509bb2/"},s.a.createElement("div",{className:"external-link linkedin-link"}," ")),s.a.createElement("a",{href:"https://twitter.com/EyubogluSabri"},s.a.createElement("div",{className:"external-link twitter-link"}," ")))),s.a.createElement("div",{className:"navbar-about"},s.a.createElement("div",{className:"text-section"},s.a.createElement("p",null,s.a.createElement("b",null,"About.")," I'm a CS PhD Student in the ",s.a.createElement("a",{href:"http://ml.stanford.edu"},"Stanford Machine Learning Group")," advised by ",s.a.createElement("a",{href:"https://cs.stanford.edu/people/chrismre/"},"Chris R\xe9")," and ",s.a.createElement("a",{href:"https://www.james-zou.com/"},"James Zou"),". I am supported by the ",s.a.createElement("a",{href:"https://www.nsfgrfp.org/"}," National Science Foundation GRFP "),"."),s.a.createElement("p",null,s.a.createElement("b",null,"Research Interests.")," I'm currently working on improving LLM ",s.a.createElement("i",null,"memory"),", the ability of a model to store and recall large amounts of user-provided information. In particular, I'm interested in the tradeoff between cost (",s.a.createElement("i",null,"e.g.")," memory consumption, decoding latency and throughput) and quality.",s.a.createElement("i",null," How should we balance this tradeoff as we scale up the amount of information we want to remember?")),s.a.createElement("p",null,"Answering this question is critical for realizing more personalized, sustainable, accessible, and effective AI. In an effort to answer it, I've spent a lot of time trying to understand the internals of how language models work. I do this by exploring the swaths of data on which they are trained and formulating simple synthetic tasks [",s.a.createElement(E,{cardId:"zoology",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),",",s.a.createElement(E,{cardId:"based",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),",",s.a.createElement(E,{cardId:"layer-looping",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),"]. Informed by this understanding, I spend (probably too much) time designing new architectures (",s.a.createElement("i",null,"e.g.")," Based) and training them from scratch [",s.a.createElement(E,{cardId:"based",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),",",s.a.createElement(E,{cardId:"monarch-mixer",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),"]. Most recently, I've shown how we can store memories in far more space-efficiently using test-time training [",s.a.createElement(E,{cardId:"cartridges",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),"]. I also have spent time developing LLM-systems that can efficiently process large amounts of information by combining multiple LLMs and LLM-generated code [",s.a.createElement(E,{cardId:"minions",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),",",s.a.createElement(E,{cardId:"evaporate",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),"]."),s.a.createElement("p",null,s.a.createElement("b",null,"Background.")," In the early days of my PhD, I had a lot of fun developing techniques (",s.a.createElement("i",null,"e.g.")," Domino [",s.a.createElement(E,{cardId:"domino",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),"], Mocha [",s.a.createElement(E,{cardId:"model-changelists",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),"]) and tools (Meerkat [",s.a.createElement(E,{cardId:"meerkat",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),']) to help deep learning practitioners identify subtle failure modes of their models. The big idea in this line of work was to use "foundation models" (e.g. CLIP, GPT-3), which were brand new at the time, to help analyze and wrangle unstructured validation data.'),s.a.createElement("p",null,"Prior to my PhD, my research focused on applying machine learning in safety-critical settings like medicine and the sciences [",s.a.createElement(E,{cardId:"pet-ct",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),", ",s.a.createElement(E,{cardId:"mutual-interactors",onHover:this.props.setHighlightedCard,onLeave:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}),"]. I was a machine learning researcher at ",s.a.createElement("a",{href:"https://flatiron.com/"},"Flatiron Health")," for a year. Before that, I completed my undergrad and master's at Stanford, where I worked with Jure Leskovec's",s.a.createElement("a",{href:"https://cs.stanford.edu/~jure/"}," SNAP Group")," and the ",s.a.createElement("a",{href:"https://aimi.stanford.edu/"},"AIMI Center"),". I'm grateful to my many mentors along the way who helped me navigate my early days in research."),s.a.createElement("p",null,s.a.createElement("b",null,"Notes.")," I serve as an advisor to ",s.a.createElement("a",{href:"https://cartesia.ai"},"Cartesia"),", a startup led by labmates that is applying ",s.a.createElement("a",{href:"https://cartesia.ai/research"},"some of our research")," to the problem of delivering real-time AI."))))}}]),a}(r.Component),C=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(h.a)(a,[{key:"render",value:function(){return s.a.createElement("div",{id:"navbar-wrapper"},s.a.createElement(k,{setHighlightedCard:this.props.setHighlightedCard,clearHighlightedCard:this.props.clearHighlightedCard,showAllPapers:this.props.showAllPapers,togglePapersView:this.props.togglePapersView,researchData:this.props.researchData}))}}]),a}(r.Component),P=(r.Component,a(14)),A=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){var e;return Object(c.a)(this,a),(e=t.call(this)).togglePapersView=function(){e.setState((function(e){return{showAllPapers:!e.showAllPapers}}))},e.setHighlightedCard=function(t){e.setState({highlightedCard:t})},e.clearHighlightedCard=function(){e.setState({highlightedCard:null})},e.state={data:P.DATA,showAllPapers:!1,highlightedCard:null},e}return Object(h.a)(a,[{key:"render",value:function(){var e=this.state,t=e.data,a=e.showAllPapers,r=e.highlightedCard,i=[],n=[],o=[];if(console.log(t),null!=t){for(var l=a?t.research:t.research.filter((function(e){return!0===e.pinned})),c=0;c<l.length;c++)i.push(s.a.createElement(b,{key:c,id:l[c].id,title:l[c].title,authors:l[c].authors,venues:l[c].venues,image:l[c].image,description:l[c].description,github:l[c].github,manuscript:l[c].manuscript,links:l[c].links,highlighted:r===l[c].id}));for(var h=0;h<t.teaching.length;h++)n.push(s.a.createElement(f,{title:t.teaching[h].title,organization:t.teaching[h].organization,school:t.teaching[h].school,year:t.teaching[h].year,image:t.teaching[h].image,description:t.teaching[h].description,github:t.teaching[h].github,website:t.teaching[h].website,links:t.teaching[h].links}));for(var d=0;d<t.software.length;d++)o.push(s.a.createElement(y,{key:d,id:t.software[d].id,title:t.software[d].title,banner:t.software[d].banner,description:t.software[d].description,github:t.software[d].github,website:t.software[d].website,pypi:t.software[d].pypi,docs:t.software[d].docs,links:t.software[d].links,highlighted:r===t.software[d].id}))}return s.a.createElement("div",{id:"home-page"},s.a.createElement(C,{setHighlightedCard:this.setHighlightedCard,clearHighlightedCard:this.clearHighlightedCard,showAllPapers:a,togglePapersView:this.togglePapersView,researchData:t.research}),s.a.createElement("div",{className:"concept-cards"},s.a.createElement("div",{id:"research-heading",className:"section-heading research-heading"}," Research "),s.a.createElement("div",{className:"research-controls"},s.a.createElement("div",{className:"papers-top-toggle-container"},s.a.createElement("button",{className:"papers-top-toggle-button ".concat(a?"":"active"),onClick:this.togglePapersView},"Selected"),s.a.createElement("button",{className:"papers-top-toggle-button ".concat(a?"active":""),onClick:this.togglePapersView},"All")),s.a.createElement("em",{id:"google-scholar",className:"google-scholar"}," For the most up-to-date list of publications, please see ",s.a.createElement("a",{href:"https://scholar.google.com/citations?user=ya1egC8AAAAJ&hl=en&authuser=1&oi=ao"},"Google Scholar"),". ")),s.a.createElement("div",{id:"research-cards-wrapper"},i),s.a.createElement("div",{className:"papers-toggle-container"},s.a.createElement("button",{className:"papers-toggle-button",onClick:this.togglePapersView},a?"\u25b2 Show selected":"\u25bc Show all")),s.a.createElement("div",{id:"software-heading",className:"section-heading"}," Software "),s.a.createElement("div",{id:"software-cards-wrapper",className:"horizontal-section"},o)))}}]),a}(r.Component),S=function(e){Object(d.a)(a,e);var t=Object(p.a)(a);function a(){return Object(c.a)(this,a),t.apply(this,arguments)}return Object(h.a)(a,[{key:"render",value:function(){return s.a.createElement(A,null)}}]),a}(r.Component),H=s.a.createElement(o.a,{basename:""},s.a.createElement("div",null,s.a.createElement(l.a,{exact:!0,path:"/",component:S})));n.a.render(H,document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then((function(e){e.unregister()}))}],[[23,1,2]]]);
//# sourceMappingURL=main.53492076.chunk.js.map